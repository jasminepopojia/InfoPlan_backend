import json
import os
from loguru import logger
from apis.xhs_pc_apis import XHS_Apis
from xhs_utils.common_util import init
from xhs_utils.data_util import handle_note_info, download_note, save_to_xlsx


class Data_Spider():
    def __init__(self):
        self.xhs_apis = XHS_Apis()

    def spider_note(self, note_url: str, cookies_str: str, proxies=None):
        """
        çˆ¬å–ä¸€ä¸ªç¬”è®°çš„ä¿¡æ¯
        :param note_url:
        :param cookies_str:
        :return:
        """
        note_info = None
        try:
            success, msg, note_info = self.xhs_apis.get_note_info(note_url, cookies_str, proxies)
            import json
            note_info_json_path = os.path.abspath(os.path.join(base_path['excel'], f'{note_url.split("/")[-1].split("?")[0]}_note_info.json'))
            with open(note_info_json_path, 'w', encoding='utf-8') as f:
                json.dump(note_info, f, ensure_ascii=False, indent=2)
            logger.info(f'ç¬”è®°ä¿¡æ¯å·²ä¿å­˜åˆ°: {note_info_json_path},{success},{msg}')
            if success:
                note_info = note_info['data']['items'][0]
                note_info['url'] = note_url
                note_info = handle_note_info(note_info)
                handle_note_info_json_path = os.path.abspath(os.path.join(base_path['excel'], f'{note_url.split("/")[-1].split("?")[0]}_handle_note_info.json'))
                with open(handle_note_info_json_path, 'w', encoding='utf-8') as f:
                    json.dump(note_info, f, ensure_ascii=False, indent=2)
                logger.info(f'handle_note_infoç¬”è®°ä¿¡æ¯å·²ä¿å­˜åˆ°: {handle_note_info_json_path}')
        except Exception as e:
            success = False
            msg = e
        logger.info(f'çˆ¬å–ç¬”è®°ä¿¡æ¯ {note_url}: {success}, msg: {msg}')
        return success, msg, note_info

    def spider_some_note(self, notes: list, cookies_str: str, base_path: dict, save_choice: str, excel_name: str = '', proxies=None):
        """
        çˆ¬å–ä¸€äº›ç¬”è®°çš„ä¿¡æ¯
        :param notes:
        :param cookies_str:
        :param base_path:
        :return:
        """
        if (save_choice == 'all' or save_choice == 'excel') and excel_name == '':
            raise ValueError('excel_name ä¸èƒ½ä¸ºç©º')
        note_list = []
        for note_url in notes:
            success, msg, note_info = self.spider_note(note_url, cookies_str, proxies)
            if note_info is not None and success:
                note_list.append(note_info)
        for note_info in note_list:
            if save_choice == 'all' or 'media' in save_choice:
                download_note(note_info, base_path['media'], save_choice)
        if save_choice == 'all' or save_choice == 'excel':
            file_path = os.path.abspath(os.path.join(base_path['excel'], f'{excel_name}.xlsx'))
            save_to_xlsx(note_list, file_path)


    def spider_user_all_note(self, user_url: str, cookies_str: str, base_path: dict, save_choice: str, excel_name: str = '', proxies=None):
        """
        çˆ¬å–ä¸€ä¸ªç”¨æˆ·çš„æ‰€æœ‰ç¬”è®°
        :param user_url:
        :param cookies_str:
        :param base_path:
        :return:
        """
        note_list = []
        try:
            success, msg, all_note_info = self.xhs_apis.get_user_latest_notes(user_url, cookies_str, limit = 5,proxies=proxies)
            import json
            user_notes_json_path = os.path.abspath(os.path.join(base_path['excel'], f'{user_url.split("/")[-1].split("?")[0]}_all_notes.json'))
            with open(user_notes_json_path, 'w', encoding='utf-8') as f:
                json.dump(all_note_info, f, ensure_ascii=False, indent=2)
            logger.info(f'ç”¨æˆ· {user_url} ç¬”è®°ä¿¡æ¯å·²ä¿å­˜åˆ°: {user_notes_json_path}')
            if success:
                logger.info(f'ç”¨æˆ· {user_url} ä½œå“æ•°é‡: {len(all_note_info)}')
                for simple_note_info in all_note_info:
                    note_url = f"https://www.xiaohongshu.com/explore/{simple_note_info['note_id']}?xsec_token={simple_note_info['xsec_token']}"
                    note_list.append(note_url)
            if save_choice == 'all' or save_choice == 'excel':
                excel_name = user_url.split('/')[-1].split('?')[0]
            self.spider_some_note(note_list, cookies_str, base_path, save_choice, excel_name, proxies)
        except Exception as e:
            success = False
            msg = e
        logger.info(f'çˆ¬å–ç”¨æˆ·æ‰€æœ‰è§†é¢‘ {user_url}: {success}, msg: {msg}')
        return note_list, success, msg

    def spider_some_search_note(self, query: str, require_num: int, cookies_str: str, base_path: dict, save_choice: str, sort_type_choice=0, note_type=0, note_time=0, note_range=0, pos_distance=0, geo: dict = None,  excel_name: str = '', proxies=None):
        """
            æŒ‡å®šæ•°é‡æœç´¢ç¬”è®°ï¼Œè®¾ç½®æ’åºæ–¹å¼å’Œç¬”è®°ç±»å‹å’Œç¬”è®°æ•°é‡
            :param query æœç´¢çš„å…³é”®è¯
            :param require_num æœç´¢çš„æ•°é‡
            :param cookies_str ä½ çš„cookies
            :param base_path ä¿å­˜è·¯å¾„
            :param sort_type_choice æ’åºæ–¹å¼ 0 ç»¼åˆæ’åº, 1 æœ€æ–°, 2 æœ€å¤šç‚¹èµ, 3 æœ€å¤šè¯„è®º, 4 æœ€å¤šæ”¶è—
            :param note_type ç¬”è®°ç±»å‹ 0 ä¸é™, 1 è§†é¢‘ç¬”è®°, 2 æ™®é€šç¬”è®°
            :param note_time ç¬”è®°æ—¶é—´ 0 ä¸é™, 1 ä¸€å¤©å†…, 2 ä¸€å‘¨å†…å¤©, 3 åŠå¹´å†…
            :param note_range ç¬”è®°èŒƒå›´ 0 ä¸é™, 1 å·²çœ‹è¿‡, 2 æœªçœ‹è¿‡, 3 å·²å…³æ³¨
            :param pos_distance ä½ç½®è·ç¦» 0 ä¸é™, 1 åŒåŸ, 2 é™„è¿‘ æŒ‡å®šè¿™ä¸ªå¿…é¡»è¦æŒ‡å®š geo
            è¿”å›æœç´¢çš„ç»“æœ
        """
        note_list = []
        try:
            success, msg, notes = self.xhs_apis.search_some_note(query, require_num, cookies_str, sort_type_choice, note_type, note_time, note_range, pos_distance, geo, proxies)
            if success:
                notes = list(filter(lambda x: x['model_type'] == "note", notes))
                logger.info(f'æœç´¢å…³é”®è¯ {query} ç¬”è®°æ•°é‡: {len(notes)}')
                for note in notes:
                    note_url = f"https://www.xiaohongshu.com/explore/{note['id']}?xsec_token={note['xsec_token']}"
                    note_list.append(note_url)
            if save_choice == 'all' or save_choice == 'excel':
                excel_name = query
            self.spider_some_note(note_list, cookies_str, base_path, save_choice, excel_name, proxies)
        except Exception as e:
            success = False
            msg = e
        logger.info(f'æœç´¢å…³é”®è¯ {query} ç¬”è®°: {success}, msg: {msg}')
        return note_list, success, msg

if __name__ == '__main__':
    """
        æ­¤æ–‡ä»¶ä¸ºçˆ¬è™«çš„å…¥å£æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ
        apis/xhs_pc_apis.py ä¸ºçˆ¬è™«çš„apiæ–‡ä»¶ï¼ŒåŒ…å«å°çº¢ä¹¦çš„å…¨éƒ¨æ•°æ®æ¥å£ï¼Œå¯ä»¥ç»§ç»­å°è£…
        apis/xhs_creator_apis.py ä¸ºå°çº¢ä¹¦åˆ›ä½œè€…ä¸­å¿ƒçš„apiæ–‡ä»¶
        æ„Ÿè°¢starå’Œfollow
    """

    cookies_str, base_path = init()
    data_spider = Data_Spider()
    """
        save_choice: all: ä¿å­˜æ‰€æœ‰çš„ä¿¡æ¯, media: ä¿å­˜è§†é¢‘å’Œå›¾ç‰‡ï¼ˆmedia-videoåªä¸‹è½½è§†é¢‘, media-imageåªä¸‹è½½å›¾ç‰‡ï¼Œmediaéƒ½ä¸‹è½½ï¼‰, excel: ä¿å­˜åˆ°excel
        save_choice ä¸º excel æˆ–è€… all æ—¶ï¼Œexcel_name ä¸èƒ½ä¸ºç©º
    """

    # # ========== æµ‹è¯•æœç´¢ç”¨æˆ·æ¥å£ ==========
    # logger.info("=" * 50)
    # logger.info("å¼€å§‹æµ‹è¯•æœç´¢ç”¨æˆ·æ¥å£")
    # logger.info("=" * 50)

    # # æµ‹è¯•æœç´¢ç”¨æˆ·ï¼ˆå•é¡µï¼‰
    # search_query = "ç¾é£Ÿ"
    # page = 1
    # logger.info(f"æœç´¢å…³é”®è¯: {search_query}, é¡µç : {page}")

    # success, msg, res_json = data_spider.xhs_apis.search_user(search_query, cookies_str, page)

    # if success:
    #     logger.info(f"æœç´¢æˆåŠŸï¼æ¶ˆæ¯: {msg}")
    #     if res_json and 'data' in res_json:
    #         # æ­£ç¡®çš„æ•°æ®è·¯å¾„ï¼šres_json['data']['users']
    #         users = res_json['data'].get('users', [])
    #         logger.info(f"æ‰¾åˆ° {len(users)} ä¸ªç”¨æˆ·")
            
    #         # æ‰“å°å‰å‡ ä¸ªç”¨æˆ·çš„ä¿¡æ¯ï¼ˆä½¿ç”¨æ­£ç¡®çš„å­—æ®µåï¼‰
    #         for i, user in enumerate(users[:3], 1):
    #             logger.info(f"ç”¨æˆ· {i}:")
    #             logger.info(f"  - ç”¨æˆ·ID: {user.get('id', 'N/A')}")
    #             logger.info(f"  - æ˜µç§°: {user.get('name', 'N/A')}")
    #             logger.info(f"  - å°çº¢ä¹¦å·: {user.get('red_id', 'N/A')}")
    #             logger.info(f"  - ç®€ä»‹: {user.get('sub_title', 'N/A')}")
    #             logger.info(f"  - ç²‰ä¸æ•°: {user.get('fans', 'N/A')}")
    #             logger.info(f"  - ç¬”è®°æ•°: {user.get('note_count', 'N/A')}")
    #             logger.info(f"  - æ›´æ–°æ—¶é—´: {user.get('update_time', 'N/A')}")
    #             logger.info(f"  - æ˜¯å¦å·²å…³æ³¨: {'æ˜¯' if user.get('followed', False) else 'å¦'}")
    #             logger.info(f"  - å¤´åƒ: {user.get('image', 'N/A')}")
    #             logger.info("-" * 30)
    #     else:
    #         logger.warning("è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
    #         if res_json:
    #             logger.warning(f"è¿”å›æ•°æ®: {res_json}")
    # else:
    #     logger.error(f"æœç´¢å¤±è´¥: {msg}")

    # logger.info("=" * 50)

    # # æµ‹è¯•æ‰¹é‡æœç´¢ç”¨æˆ·ï¼ˆè·å–æŒ‡å®šæ•°é‡çš„ç”¨æˆ·ï¼‰
    # logger.info("å¼€å§‹æµ‹è¯•æ‰¹é‡æœç´¢ç”¨æˆ·æ¥å£")
    # logger.info("=" * 50)

    # require_num = 20
    # logger.info(f"æœç´¢å…³é”®è¯: {search_query}, éœ€è¦æ•°é‡: {require_num}")

    # success, msg, user_list = data_spider.xhs_apis.search_some_user(search_query, require_num, cookies_str)

    # if success:
    #     logger.info(f"æ‰¹é‡æœç´¢æˆåŠŸï¼æ¶ˆæ¯: {msg}")
    #     logger.info(f"å…±è·å– {len(user_list)} ä¸ªç”¨æˆ·")
        
    #     # æ‰“å°ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯ï¼ˆä½¿ç”¨æ­£ç¡®çš„å­—æ®µåï¼‰
    #     if user_list:
    #         logger.info("\nç”¨æˆ·åˆ—è¡¨é¢„è§ˆï¼ˆå‰5ä¸ªï¼‰:")
    #         for i, user in enumerate(user_list[:5], 1):
    #             user_id = user.get('id', 'N/A')
    #             user_name = user.get('name', 'N/A')
    #             user_fans = user.get('fans', 'N/A')
    #             user_notes = user.get('note_count', 'N/A')
    #             logger.info(f"{i}. {user_name} (ID: {user_id}, ç²‰ä¸: {user_fans}, ç¬”è®°: {user_notes})")
            
    #         # ç»Ÿè®¡ä¿¡æ¯
    #         logger.info("\nç»Ÿè®¡ä¿¡æ¯:")
    #         total_followed = sum(1 for user in user_list if user.get('followed', False))
    #         logger.info(f"  - å·²å…³æ³¨ç”¨æˆ·æ•°: {total_followed}")
    #         logger.info(f"  - æœªå…³æ³¨ç”¨æˆ·æ•°: {len(user_list) - total_followed}")
            
    #         # ç²‰ä¸æ•°ç»Ÿè®¡ï¼ˆå°è¯•è§£æï¼‰
    #         try:
    #             fans_list = []
    #             for user in user_list:
    #                 fans_str = user.get('fans', '0')
    #                 if 'ä¸‡' in fans_str:
    #                     fans_num = float(fans_str.replace('ä¸‡', '')) * 10000
    #                 else:
    #                     fans_num = float(fans_str) if fans_str.replace('.', '').isdigit() else 0
    #                 fans_list.append(fans_num)
                
    #             if fans_list:
    #                 avg_fans = sum(fans_list) / len(fans_list)
    #                 max_fans = max(fans_list)
    #                 min_fans = min(fans_list)
    #                 logger.info(f"  - å¹³å‡ç²‰ä¸æ•°: {avg_fans/10000:.2f}ä¸‡")
    #                 logger.info(f"  - æœ€å¤šç²‰ä¸æ•°: {max_fans/10000:.2f}ä¸‡")
    #                 logger.info(f"  - æœ€å°‘ç²‰ä¸æ•°: {min_fans/10000:.2f}ä¸‡")
    #         except Exception as e:
    #             logger.warning(f"ç²‰ä¸æ•°ç»Ÿè®¡å¤±è´¥: {e}")
    # else:
    #     logger.error(f"æ‰¹é‡æœç´¢å¤±è´¥: {msg}")

    # logger.info("=" * 50)
    # logger.info("æœç´¢ç”¨æˆ·æ¥å£æµ‹è¯•å®Œæˆ")
    # logger.info("=" * 50)

    # # ========== æµ‹è¯•è·å–ç”¨æˆ·ä¿¡æ¯æ¥å£ ==========
    # logger.info("\n" + "=" * 50)
    # logger.info("å¼€å§‹æµ‹è¯•è·å–ç”¨æˆ·ä¿¡æ¯æ¥å£")
    # logger.info("=" * 50)
    
    # # æµ‹è¯•1: è·å–ç”¨æˆ·è‡ªå·±çš„ä¿¡æ¯1 (get_user_self_info)
    # logger.info("\nã€æµ‹è¯•1ã€‘è·å–ç”¨æˆ·è‡ªå·±çš„ä¿¡æ¯1 (get_user_self_info)")
    # logger.info("-" * 50)
    # success, msg, res_json = data_spider.xhs_apis.get_user_self_info(cookies_str)
    
    # if success:
    #     logger.info(f"âœ… è¯·æ±‚æˆåŠŸï¼æ¶ˆæ¯: {msg}")
    #     if res_json and 'data' in res_json:
    #         user_data = res_json['data']
    #         logger.info("\nğŸ“‹ ç”¨æˆ·ä¿¡æ¯è¯¦æƒ…:")
    #         logger.info(f"  - ç”¨æˆ·ID: {user_data.get('user_id', 'N/A')}")
    #         logger.info(f"  - æ˜µç§°: {user_data.get('nickname', 'N/A')}")
    #         logger.info(f"  - ç®€ä»‹: {user_data.get('desc', 'N/A')}")
    #         logger.info(f"  - å¤´åƒ: {user_data.get('imageb', 'N/A')}")
    #         logger.info(f"  - ç²‰ä¸æ•°: {user_data.get('follows', 'N/A')}")
    #         logger.info(f"  - å…³æ³¨æ•°: {user_data.get('followed', 'N/A')}")
    #         logger.info(f"  - è·èµæ•°: {user_data.get('liked', 'N/A')}")
    #         logger.info(f"  - ç¬”è®°æ•°: {user_data.get('notes', 'N/A')}")
    #         logger.info(f"  - æ”¶è—æ•°: {user_data.get('collected', 'N/A')}")
            
    #         # æ‰“å°å®Œæ•´ JSONï¼ˆæ ¼å¼åŒ–ï¼‰
    #         logger.info("\nğŸ“„ å®Œæ•´è¿”å›æ•°æ®:")
    #         logger.info(json.dumps(res_json, ensure_ascii=False, indent=2))
    #     else:
    #         logger.warning("âš ï¸ è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
    #         logger.info(f"è¿”å›å†…å®¹: {res_json}")
    # else:
    #     logger.error(f"âŒ è¯·æ±‚å¤±è´¥: {msg}")
    #     if res_json:
    #         logger.info(f"è¿”å›å†…å®¹: {res_json}")
    
    # # æµ‹è¯•2: è·å–ç”¨æˆ·è‡ªå·±çš„ä¿¡æ¯2 (get_user_self_info2)
    # logger.info("\n" + "-" * 50)
    # logger.info("ã€æµ‹è¯•2ã€‘è·å–ç”¨æˆ·è‡ªå·±çš„ä¿¡æ¯2 (get_user_self_info2)")
    # logger.info("-" * 50)
    # success, msg, res_json = data_spider.xhs_apis.get_user_self_info2(cookies_str)
    
    # if success:
    #     logger.info(f"âœ… è¯·æ±‚æˆåŠŸï¼æ¶ˆæ¯: {msg}")
    #     if res_json and 'data' in res_json:
    #         user_data = res_json['data']
    #         logger.info("\nğŸ“‹ ç”¨æˆ·ä¿¡æ¯è¯¦æƒ…:")
    #         logger.info(f"  - ç”¨æˆ·ID: {user_data.get('id', 'N/A')}")
    #         logger.info(f"  - æ˜µç§°: {user_data.get('nickname', 'N/A')}")
    #         logger.info(f"  - ç®€ä»‹: {user_data.get('desc', 'N/A')}")
    #         logger.info(f"  - å¤´åƒ: {user_data.get('imageb', 'N/A')}")
    #         logger.info(f"  - ç²‰ä¸æ•°: {user_data.get('follows', 'N/A')}")
    #         logger.info(f"  - å…³æ³¨æ•°: {user_data.get('followed', 'N/A')}")
    #         logger.info(f"  - è·èµæ•°: {user_data.get('liked', 'N/A')}")
    #         logger.info(f"  - ç¬”è®°æ•°: {user_data.get('notes', 'N/A')}")
            
    #         # æ‰“å°å®Œæ•´ JSONï¼ˆæ ¼å¼åŒ–ï¼‰
    #         logger.info("\nğŸ“„ å®Œæ•´è¿”å›æ•°æ®:")
    #         logger.info(json.dumps(res_json, ensure_ascii=False, indent=2))
    #     else:
    #         logger.warning("âš ï¸ è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
    #         logger.info(f"è¿”å›å†…å®¹: {res_json}")
    # else:
    #     logger.error(f"âŒ è¯·æ±‚å¤±è´¥: {msg}")
    #     if res_json:
    #         logger.info(f"è¿”å›å†…å®¹: {res_json}")
    
    # æµ‹è¯•3: è·å–æŒ‡å®šç”¨æˆ·çš„ä¿¡æ¯ (get_user_info)
    # å…ˆä»æœç´¢ç»“æœä¸­è·å–ä¸€ä¸ª user_idï¼Œæˆ–è€…ä½¿ç”¨ä¸€ä¸ªç¤ºä¾‹ user_id
    # logger.info("\n" + "-" * 50)
    # logger.info("ã€æµ‹è¯•3ã€‘è·å–æŒ‡å®šç”¨æˆ·çš„ä¿¡æ¯ (get_user_info)")
    # logger.info("-" * 50)
    
    # # å…ˆæœç´¢ç”¨æˆ·è·å–ä¸€ä¸ª user_id
    # test_user_id = None
    # search_query_for_user = "ç¾é£Ÿ"
    # logger.info(f"å…ˆæœç´¢å…³é”®è¯ '{search_query_for_user}' è·å–ä¸€ä¸ªç”¨æˆ·ID...")
    
    # success, msg, search_res = data_spider.xhs_apis.search_user(search_query_for_user, cookies_str, page=1)
    # logger.info("\nğŸ“„ å®Œæ•´è¿”å›æ•°æ®:")
    # logger.info(json.dumps(search_res, ensure_ascii=False, indent=2))
    # if success and search_res and 'data' in search_res:
    #     users = search_res['data'].get('users', [])
    #     if users:
    #         test_user_id = users[0].get('id')
    #         logger.info(f"âœ… æ‰¾åˆ°ç”¨æˆ·ID: {test_user_id}")
    #         logger.info(f"   ç”¨æˆ·æ˜µç§°: {users[0].get('name', 'N/A')}")
    #     else:
    #         logger.warning("âš ï¸ æœç´¢ç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·ï¼Œå°†ä½¿ç”¨ç¤ºä¾‹ user_id")
    #         test_user_id = "64c3f392000000002b009e45"  # ç¤ºä¾‹ user_id
    # else:
    #     logger.warning("âš ï¸ æœç´¢å¤±è´¥ï¼Œå°†ä½¿ç”¨ç¤ºä¾‹ user_id")
    #     test_user_id = "64c3f392000000002b009e45"  # ç¤ºä¾‹ user_id
    
    # if test_user_id:
    #     logger.info(f"\nä½¿ç”¨ç”¨æˆ·ID: {test_user_id} è¿›è¡Œæµ‹è¯•")
    #     success, msg, res_json = data_spider.xhs_apis.get_user_info(test_user_id, cookies_str)
        
    #     if success:
    #         logger.info(f"âœ… è¯·æ±‚æˆåŠŸï¼æ¶ˆæ¯: {msg}")
    #         if res_json and 'data' in res_json:
    #             user_data = res_json['data']
    #             logger.info("\nğŸ“‹ ç”¨æˆ·ä¿¡æ¯è¯¦æƒ…:")
    #             logger.info(f"  - ç”¨æˆ·ID: {user_data.get('user_id', 'N/A')}")
    #             logger.info(f"  - æ˜µç§°: {user_data.get('nickname', 'N/A')}")
    #             logger.info(f"  - ç®€ä»‹: {user_data.get('desc', 'N/A')}")
    #             logger.info(f"  - å¤´åƒ: {user_data.get('imageb', 'N/A')}")
    #             logger.info(f"  - ç²‰ä¸æ•°: {user_data.get('follows', 'N/A')}")
    #             logger.info(f"  - å…³æ³¨æ•°: {user_data.get('followed', 'N/A')}")
    #             logger.info(f"  - è·èµæ•°: {user_data.get('liked', 'N/A')}")
    #             logger.info(f"  - ç¬”è®°æ•°: {user_data.get('notes', 'N/A')}")
    #             logger.info(f"  - æ”¶è—æ•°: {user_data.get('collected', 'N/A')}")
                
    #             # æ‰“å°å®Œæ•´ JSONï¼ˆæ ¼å¼åŒ–ï¼‰
    #             logger.info("\nğŸ“„ å®Œæ•´è¿”å›æ•°æ®:")
    #             logger.info(json.dumps(res_json, ensure_ascii=False, indent=2))
    #         else:
    #             logger.warning("âš ï¸ è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
    #             logger.info(f"è¿”å›å†…å®¹: {res_json}")
    #     else:
    #         logger.error(f"âŒ è¯·æ±‚å¤±è´¥: {msg}")
    #         if res_json:
    #             logger.info(f"è¿”å›å†…å®¹: {res_json}")
    # else:
    #     logger.error("âŒ æ— æ³•è·å–æµ‹è¯•ç”¨çš„ user_id")
    
    # logger.info("\n" + "=" * 50)
    # logger.info("è·å–ç”¨æˆ·ä¿¡æ¯æ¥å£æµ‹è¯•å®Œæˆ")
    # logger.info("=" * 50)

    # # ========== æµ‹è¯•è·å–ç”¨æˆ·æ”¶è—ç¬”è®°åˆ—è¡¨å’Œå…³æ³¨åˆ—è¡¨ ==========
    # logger.info("\n" + "=" * 50)
    # logger.info("å¼€å§‹æµ‹è¯•è·å–ç”¨æˆ·æ”¶è—ç¬”è®°åˆ—è¡¨å’Œå…³æ³¨åˆ—è¡¨")
    # logger.info("=" * 50)
    
    # # å…ˆè·å–å½“å‰ç”¨æˆ·çš„ user_id
    # test_user_id = None
    # logger.info("\nã€æ­¥éª¤1ã€‘è·å–å½“å‰ç”¨æˆ·çš„ user_id...")
    # success, msg, self_info = data_spider.xhs_apis.get_user_self_info2(cookies_str)
    
    # if success and self_info and 'data' in self_info:
    #     test_user_id = self_info['data'].get('user_id')
    #     logger.info(f"âœ… è·å–åˆ°å½“å‰ç”¨æˆ·ID: {test_user_id}")
    # else:
    #     logger.warning("âš ï¸ æ— æ³•è·å–å½“å‰ç”¨æˆ·IDï¼Œå°†ä½¿ç”¨ç¤ºä¾‹ user_id")
    #     # å¦‚æœæ— æ³•è·å–ï¼Œå°è¯•ä»æœç´¢ç»“æœè·å–
    #     search_query_for_user = "ç¾é£Ÿ"
    #     success, msg, search_res = data_spider.xhs_apis.search_user(search_query_for_user, cookies_str, page=1)
    #     if success and search_res and 'data' in search_res:
    #         users = search_res['data'].get('users', [])
    #         if users:
    #             test_user_id = users[0].get('user_id')
    #             logger.info(f"âœ… ä»æœç´¢ç»“æœè·å–åˆ°ç”¨æˆ·ID: {test_user_id}")
    #         else:
    #             test_user_id = "65a75fca000000000803082a"  # ç¤ºä¾‹ user_id
    #     else:
    #         test_user_id = "65a75fca000000000803082a"  # ç¤ºä¾‹ user_id
    
    # if test_user_id:
    #     # æµ‹è¯•1: è·å–ç”¨æˆ·æ”¶è—ç¬”è®°åˆ—è¡¨ï¼ˆå•é¡µï¼‰
    #     logger.info("\n" + "-" * 50)
    #     logger.info("ã€æµ‹è¯•1ã€‘è·å–ç”¨æˆ·æ”¶è—ç¬”è®°åˆ—è¡¨ï¼ˆå•é¡µï¼‰")
    #     logger.info("-" * 50)
    #     logger.info(f"ç”¨æˆ·ID: {test_user_id}")
        
    #     success, msg, res_json = data_spider.xhs_apis.get_user_collect_notes(test_user_id, cookies_str)
        
    #     if success:
    #         logger.info(f"âœ… è¯·æ±‚æˆåŠŸï¼æ¶ˆæ¯: {msg}")
    #         if res_json and 'data' in res_json:
    #             data = res_json['data']
    #             notes = data.get('notes', [])
    #             logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(notes)} æ¡æ”¶è—ç¬”è®°")
                
    #             # æ‰“å°å‰å‡ æ¡ç¬”è®°ä¿¡æ¯
    #             for i, note in enumerate(notes[:3], 1):
    #                 logger.info(f"\næ”¶è—ç¬”è®° {i}:")
    #                 logger.info(f"  - ç¬”è®°ID: {note.get('note_id', 'N/A')}")
    #                 logger.info(f"  - æ ‡é¢˜: {note.get('title', 'N/A')}")
    #                 logger.info(f"  - ç±»å‹: {note.get('type', 'N/A')}")
    #                 logger.info(f"  - ç‚¹èµæ•°: {note.get('liked_count', 'N/A')}")
    #                 logger.info(f"  - æ”¶è—æ•°: {note.get('collected_count', 'N/A')}")
    #                 logger.info(f"  - è¯„è®ºæ•°: {note.get('comments_count', 'N/A')}")
                
    #             logger.info(f"\nğŸ“„ å®Œæ•´è¿”å›æ•°æ®ï¼ˆå‰1000å­—ç¬¦ï¼‰:")
    #             json_str = json.dumps(res_json, ensure_ascii=False, indent=2)
    #             logger.info(json_str[:1000] + ("..." if len(json_str) > 1000 else ""))
    #         else:
    #             logger.warning("âš ï¸ è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
    #             logger.info(f"è¿”å›å†…å®¹: {res_json}")
    #     else:
    #         logger.error(f"âŒ è¯·æ±‚å¤±è´¥: {msg}")
    #         if res_json:
    #             logger.info(f"è¿”å›å†…å®¹: {res_json}")
        
    #     # æµ‹è¯•2: è·å–ç”¨æˆ·æ‰€æœ‰æ”¶è—ç¬”è®°
    #     logger.info("\n" + "-" * 50)
    #     logger.info("ã€æµ‹è¯•2ã€‘è·å–ç”¨æˆ·æ‰€æœ‰æ”¶è—ç¬”è®°")
    #     logger.info("-" * 50)
    #     logger.info(f"ç”¨æˆ·ID: {test_user_id}")
        
    #     success, msg, note_list = data_spider.xhs_apis.get_user_all_collect_notes(test_user_id, cookies_str)
        
    #     if success:
    #         logger.info(f"âœ… è¯·æ±‚æˆåŠŸï¼æ¶ˆæ¯: {msg}")
    #         logger.info(f"ğŸ“‹ å…±è·å– {len(note_list)} æ¡æ”¶è—ç¬”è®°")
            
    #         if note_list:
    #             logger.info("\næ”¶è—ç¬”è®°åˆ—è¡¨é¢„è§ˆï¼ˆå‰5æ¡ï¼‰:")
    #             for i, note in enumerate(note_list[:5], 1):
    #                 logger.info(f"{i}. {note.get('display_title', 'N/A')} (ID: {note.get('note_id', 'N/A')})")
    #     else:
    #         logger.error(f"âŒ è¯·æ±‚å¤±è´¥: {msg}")
    
    # else:
    #     logger.error("âŒ æ— æ³•è·å–æµ‹è¯•ç”¨çš„ user_id")
    
    # logger.info("\n" + "=" * 50)
    # logger.info("è·å–ç”¨æˆ·æ”¶è—ç¬”è®°åˆ—è¡¨å’Œå…³æ³¨åˆ—è¡¨æµ‹è¯•å®Œæˆ")
    # logger.info("=" * 50)

    # ========== ä»¥ä¸‹ä¸ºåŸæœ‰æµ‹è¯•ä»£ç ï¼ˆå·²æ³¨é‡Šï¼‰ ==========
    # # 1 çˆ¬å–åˆ—è¡¨çš„æ‰€æœ‰ç¬”è®°ä¿¡æ¯ ç¬”è®°é“¾æ¥ å¦‚ä¸‹æ‰€ç¤º æ³¨æ„æ­¤urlä¼šè¿‡æœŸï¼
    # notes = [
    #     r'https://www.xiaohongshu.com/explore/683fe17f0000000023017c6a?xsec_token=ABBr_cMzallQeLyKSRdPk9fwzA0torkbT_ubuQP1ayvKA=&xsec_source=pc_user',
    # ]
    # data_spider.spider_some_note(notes, cookies_str, base_path, 'all', 'test')

    # 2 çˆ¬å–ç”¨æˆ·çš„æ‰€æœ‰ç¬”è®°ä¿¡æ¯ ç”¨æˆ·é“¾æ¥ å¦‚ä¸‹æ‰€ç¤º æ³¨æ„æ­¤urlä¼šè¿‡æœŸï¼
    # user_url = 'https://www.xiaohongshu.com/user/profile/64c3f392000000002b009e45?xsec_token=AB-GhAToFu07JwNk_AMICHnp7bSTjVz2beVIDBwSyPwvM=&xsec_source=pc_feed'
    user_url = 'https://www.xiaohongshu.com/user/profile/5fcc82fa000000000101dc00?xsec_token=ABpui90HV_J-zs9tYIk6ITzTsoz_co3aHcSneR8ykIaT8=&xsec_source=pc_feed'
    data_spider.spider_user_all_note(user_url, cookies_str, base_path, 'all')

    # # 3 æœç´¢æŒ‡å®šå…³é”®è¯çš„ç¬”è®°
    # query = "æ¦´è²"
    # query_num = 10
    # sort_type_choice = 0  # 0 ç»¼åˆæ’åº, 1 æœ€æ–°, 2 æœ€å¤šç‚¹èµ, 3 æœ€å¤šè¯„è®º, 4 æœ€å¤šæ”¶è—
    # note_type = 0 # 0 ä¸é™, 1 è§†é¢‘ç¬”è®°, 2 æ™®é€šç¬”è®°
    # note_time = 0  # 0 ä¸é™, 1 ä¸€å¤©å†…, 2 ä¸€å‘¨å†…å¤©, 3 åŠå¹´å†…
    # note_range = 0  # 0 ä¸é™, 1 å·²çœ‹è¿‡, 2 æœªçœ‹è¿‡, 3 å·²å…³æ³¨
    # pos_distance = 0  # 0 ä¸é™, 1 åŒåŸ, 2 é™„è¿‘ æŒ‡å®šè¿™ä¸ª1æˆ–2å¿…é¡»è¦æŒ‡å®š geo
    # # geo = {
    # #     # ç»çº¬åº¦
    # #     "latitude": 39.9725,
    # #     "longitude": 116.4207
    # # }
    # data_spider.spider_some_search_note(query, query_num, cookies_str, base_path, 'all', sort_type_choice, note_type, note_time, note_range, pos_distance, geo=None)
